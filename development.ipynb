{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Simple baseline with Landsat and Bioclimatic Cubes + Sentinel images [0.31626]\n","\n","Following the three provided baselies with different modalities, we have provide a multimodal approch based on \"siamiese\" network with multiple inputs and simple shared \"decoder\". The links for the separated baselines are as follows:\n","\n","- [Baseline with Bioclimatic Cubes [0.25784]](https://www.kaggle.com/code/picekl/baseline-with-bioclimatic-cubes-0-25784)\n","- [Baseline with Landsat Cubes [0.26424]](https://www.kaggle.com/code/picekl/baseline-with-landsat-cubes-0-26424)\n","- [Baseline with Sentinel Images [0.23594]](https://www.kaggle.com/code/picekl/baseline-with-sentinel-images-0-23594)\n","\n","**Considering the significant extent for enhancing performance of this baseline, we encourage you to experiment with various techniques, architectures, losses, etc.**\n","\n","#### **Have Fun!**"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-05-01T13:30:07.054038Z","iopub.status.busy":"2024-05-01T13:30:07.053659Z","iopub.status.idle":"2024-05-01T13:30:07.058148Z","shell.execute_reply":"2024-05-01T13:30:07.057269Z","shell.execute_reply.started":"2024-05-01T13:30:07.054008Z"}},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Data description\n","\n","## Landsat time series\n","\n","Satellite time series data includes over 20 years of Landsat satellite imagery extracted from [Ecodatacube](https://stac.ecodatacube.eu/).\n","The data was acquired through the Landsat satellite program and pre-processed by Ecodatacube to produce raster files scaled to the entire European continent and projected into a unique CRS.\n","\n","Since the original rasters require a high amount of disk space, we extracted the data points from each spectral band corresponding to all PA and PO locations (i.e., GPS coordinates) and aggregated them in (i) CSV files and (ii) data cubes as tensor objects. Each data point corresponds to the mean value of Landsat's observations at the given location for three months before the given time; e.g., the value of a time series element under column 2012_4 will represent the mean value for that element from October 2012 to December 2012.\n","\n","In this notebook, we will work with just the cubes. The cubes are structured as follows.\n","**Shape**: `(n_bands, n_quarters, n_years)` where:\n","- `n_bands` = 6 comprising [`red`, `green`, `blue`, `nir`, `swir1`, `swir2`]\n","- `n_quarters` = 4 \n","    - *Quarter 1*: December 2 of previous year until March 20 of current year (winter season proxy),\n","    - *Quarter 2*: March 21 until June 24 of current year (spring season proxy),\n","    - *Quarter 3*: June 25 until September 12 of current year (summer season proxy),\n","    - *Quarter 4*: September 13 until December 1 of current year (fall season proxy).\n","- `n_years` = 21 (ranging from 2000 to 2020)\n","\n","The datacubes can simply be loaded as tensors using PyTorch with the following command :\n","\n","```python\n","import torch\n","torch.load('path_to_file.pt')\n","```\n","\n","**References:**\n","- *Traceability (lineage): This dataset is a seasonally aggregated and gapfilled version of the Landsat GLAD analysis-ready data product presented by Potapov et al., 2020 ( https://doi.org/10.3390/rs12030426 ).*\n","- *Scientific methodology: The Landsat GLAD ARD dataset was aggregated and harmonized using the eumap python package (available at https://eumap.readthedocs.io/en/latest/ ). The full process of gapfilling and harmonization is described in detail in Witjes et al., 2022 (in review, preprint available at https://doi.org/10.21203/rs.3.rs-561383/v3 ).*\n","- *Ecodatacube.eu: Analysis-ready open environmental data cube for Europe (https://doi.org/10.21203/rs.3.rs-2277090/v3).*\n","\n","\n","## Bioclimatic time series\n","\n","The Bioclimatic Cubes are created from **four** monthly GeoTIFF CHELSA (https://chelsa-climate.org/timeseries/) time series climatic rasters with a resolution of 30 arc seconds, i.e. approximately 1km. The four variables are the precipitation (pr), maximum- (taxmax), minimum- (tasmin), and mean (tax) daily temperatures per month from January 2000 to June 2019. We provide the data in three forms: (i) raw rasters (GeoTiff images), (ii) CSV file with pre-extracted values for each location, i.e., surveyId, and (iii) data cubes as tensor object (.pt).\n","\n","In this notebook, we will work with just the cubes. The cubes are structured as follows.\n","**Shape**: `(n_year, n_month, n_bio)` where:\n","- `n_year` = 19 (ranging from 2000 to 2018)\n","- `n_month` = 12 (ranging from January 01 to December 12)\n","- `n_bio` = 4 comprising [`pr` (precipitation), `tas` (mean daily air temperature), `tasmin`, `tasmax`]\n","\n","The datacubes can simply be loaded as tensors using PyTorch with the following command :\n","\n","```python\n","import torch\n","torch.load('path_to_file.pt')\n","```\n","\n","**References:**\n","- *Karger, D.N., Conrad, O., Böhner, J., Kawohl, T., Kreft, H., Soria-Auza, R.W., Zimmermann, N.E., Linder, P., Kessler, M. (2017): Climatologies at high resolution for the Earth land surface areas. Scientific Data. 4 170122. https://doi.org/10.1038/sdata.2017.122*\n","\n","- *Karger D.N., Conrad, O., Böhner, J., Kawohl, T., Kreft, H., Soria-Auza, R.W., Zimmermann, N.E, Linder, H.P., Kessler, M. Data from: Climatologies at high resolution for the earth’s land surface areas. Dryad Digital Repository. http://dx.doi.org/doi:10.5061/dryad.kd1d4*\n","\n","\n","## Sentinel Image Patches\n","\n","The Sentinel Image data was acquired through the Sentinel2 satellite program and pre-processed by [Ecodatacube](https://stac.ecodatacube.eu/) to produce raster files scaled to the entire European continent and projected into a unique CRS. We filtered the data in order to pick patches from each spectral band corresponding to a location ((lon, lat) GPS coordinates) and a date matching that of our occurrences', and split them into JPEG files (RGB in 3-channels .jpeg files and NIR in single-channel .jpeg files) with a 128x128 resolution. The images were converted from sentinel uint15 to uint8 by clipping data pixel values over 10000 and applying a gamma correction of 2.5.\n","\n","The data can simply be loaded using the following method:\n","\n","```python\n","def construct_patch_path(output_path, survey_id):\n","    \"\"\"Construct the patch file path based on survey_id as './CD/AB/XXXXABCD.jpeg'\"\"\"\n","    path = output_path\n","    for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n","        path = os.path.join(path, d)\n","\n","    path = os.path.join(path, f\"{survey_id}.jpeg\")\n","\n","    return path\n","```\n","\n","**References:**\n","- *Traceability (lineage): The dataset was produced entirely by mosaicking and seasonally aggregating imagery from the Sentinel-2 Level-2A product (https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/product-types/level-2a)*\n","- *Ecodatacube.eu: Analysis-ready open environmental data cube for Europe (https://doi.org/10.21203/rs.3.rs-2277090/v3)*"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:07.29831Z","start_time":"2024-04-30T21:25:05.354584Z"},"execution":{"iopub.execute_input":"2024-05-13T17:47:40.265752Z","iopub.status.busy":"2024-05-13T17:47:40.265415Z","iopub.status.idle":"2024-05-13T17:47:47.416429Z","shell.execute_reply":"2024-05-13T17:47:47.415517Z","shell.execute_reply.started":"2024-05-13T17:47:40.265716Z"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'./runs//trial-20240525_171152-80b9ccec//'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import datetime\n","import json\n","import os\n","import shutil\n","import uuid\n","from typing import Literal\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset, random_split\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm.autonotebook import tqdm\n","\n","RUN_TYPE = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"Localhost\")\n","DEBUG = RUN_TYPE in (\n","    \"Interactive\",\n","    \"Localhost\",\n",")\n","\n","DEBUG = False\n","experiment_name = None\n","data_dir = \"/kaggle/input/geolifeclef-2024\"\n","output_dir = \".\"\n","\n","if experiment_name is None:\n","    experiment_name = (\n","        f\"/{'trial' if DEBUG else 'run'}-\"\n","        f\"{datetime.datetime.now().strftime(r'%Y%m%d_%H%M%S')}-{uuid.uuid4().hex[:8]}/\"\n","    )\n","if RUN_TYPE == \"Localhost\":\n","    data_dir = \"./data/\"\n","    output_dir = f\"./runs/{experiment_name}/\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","CONFIG = {\n","    \"comment\": \"Baseline + Improved sentinel normalization +\"\n","    \" k-fold validation + impute with mean + 1/pos_weight\",\n","    \"seed\": 151,\n","    \"run_type\": RUN_TYPE,\n","    \"debug\": DEBUG,\n","    \"num_classes\": 11255,\n","    \"sentinel_transforms\": transforms.Compose(\n","        [\n","            transforms.ToTensor(),\n","            transforms.Normalize(\n","                mean=(0.449, 0.485, 0.456, 0.406), std=(0.226, 0.229, 0.224, 0.225)\n","            ),\n","        ]\n","    ),\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"learning_rate\": 3e-4,\n","    \"num_epochs\": 5 if DEBUG else 50,\n","    \"train_val_split\": 0.85,\n","    \"batch_size\": 128,\n","    \"early_stopping_delay\": 3,\n","}\n","\n","num_classes = CONFIG[\"num_classes\"]\n","seed = CONFIG[\"seed\"]\n","device = CONFIG[\"device\"]\n","tb_writer = SummaryWriter(log_dir=output_dir)\n","SENTINEL_TRANSFORMS = CONFIG[\"sentinel_transforms\"]\n","if not os.path.exists(config_path := os.path.join(output_dir, \"config.json\")):\n","    with open(os.path.join(output_dir, \"config.json\"), \"w\") as fp:\n","        json.dump(\n","            CONFIG,\n","            fp,\n","            default=str,\n","        )\n","try:\n","    shutil.copyfile(__vsc_ipynb_file__, os.path.join(output_dir, \"code.ipynb\"))\n","except NameError:\n","    ...\n","output_dir"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T17:47:47.446265Z","iopub.status.busy":"2024-05-13T17:47:47.445986Z","iopub.status.idle":"2024-05-13T17:47:47.482145Z","shell.execute_reply":"2024-05-13T17:47:47.481426Z","shell.execute_reply.started":"2024-05-13T17:47:47.446242Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed):\n","    # Set seed for Python's built-in random number generator\n","    torch.manual_seed(seed)\n","    # Set seed for numpy\n","    np.random.seed(seed)\n","    # Set seed for CUDA if available\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","        # Set cuDNN's random number generator seed for deterministic behavior\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare custom dataset loader\n","\n","We have to slightly update the Dataset to provide the relevant data in the appropriate format."]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:32.627928Z","start_time":"2024-04-30T21:25:32.612131Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-13T17:47:47.418632Z","iopub.status.busy":"2024-05-13T17:47:47.4182Z","iopub.status.idle":"2024-05-13T17:47:47.444945Z","shell.execute_reply":"2024-05-13T17:47:47.443977Z","shell.execute_reply.started":"2024-05-13T17:47:47.418607Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["def construct_patch_path(data_path, survey_id):\n","    \"\"\"Construct the patch file path based on plot_id as './CD/AB/XXXXABCD.jpeg'.\"\"\"\n","    survey_id = str(survey_id)\n","\n","    return os.path.join(\n","        data_path, survey_id[-2:], survey_id[-4:-2], f\"{survey_id}.jpeg\"\n","    )\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(\n","        self,\n","        tab,\n","        bioclim_data_dir,\n","        landsat_data_dir,\n","        sentinel_data_dir,\n","        metadata,\n","        transform=None,\n","    ):\n","        self.tab = tab\n","        self.transform = transform\n","        self.sentinel_transform = transform = SENTINEL_TRANSFORMS\n","\n","        self.bioclim_data_dir = bioclim_data_dir\n","        self.landsat_data_dir = landsat_data_dir\n","        self.sentinel_data_dir = sentinel_data_dir\n","        self.metadata = metadata\n","        self.metadata = self.metadata.dropna(subset=\"speciesId\").reset_index(drop=True)\n","        self.metadata[\"speciesId\"] = self.metadata[\"speciesId\"].astype(int)\n","        self.label_dict = (\n","            self.metadata.groupby(\"surveyId\")[\"speciesId\"].apply(list).to_dict()\n","        )\n","\n","        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(\n","            drop=True\n","        )\n","\n","    def __len__(self):\n","        return len(self.metadata)\n","\n","    def __getitem__(self, idx):\n","        survey_id = self.metadata.surveyId[idx]\n","        tab = torch.Tensor(\n","            self.tab[self.tab[\"surveyId\"] == survey_id].iloc[:, 1:].values[0]\n","        )\n","\n","        landsat_sample = torch.nan_to_num(\n","            torch.load(\n","                os.path.join(\n","                    self.landsat_data_dir,\n","                    f\"GLC24-PA-train-landsat-time-series_{survey_id}_cube.pt\",\n","                )\n","            )\n","        )\n","        bioclim_sample = torch.nan_to_num(\n","            torch.load(\n","                os.path.join(\n","                    self.bioclim_data_dir,\n","                    f\"GLC24-PA-train-bioclimatic_monthly_{survey_id}_cube.pt\",\n","                )\n","            )\n","        )\n","\n","        rgb_sample = np.array(\n","            Image.open(construct_patch_path(self.sentinel_data_dir, survey_id))\n","        )\n","        nir_sample = np.array(\n","            Image.open(\n","                construct_patch_path(\n","                    self.sentinel_data_dir.replace(\"rgb\", \"nir\").replace(\"RGB\", \"NIR\"),\n","                    survey_id,\n","                )\n","            )\n","        )\n","        sentinel_sample = np.concatenate((nir_sample[..., None], rgb_sample), axis=2)\n","\n","        species_ids = self.label_dict.get(\n","            survey_id, []\n","        )  # Get list of species IDs for the survey ID\n","        label = torch.zeros(num_classes)  # Initialize label tensor\n","        for species_id in species_ids:\n","            label_id = species_id\n","            label[label_id] = (\n","                1  # Set the corresponding class index to 1 for each species\n","            )\n","\n","        if isinstance(landsat_sample, torch.Tensor):\n","            landsat_sample = landsat_sample.permute(\n","                1, 2, 0\n","            )  # Change tensor shape from (C, H, W) to (H, W, C)\n","            landsat_sample = landsat_sample.numpy()  # Convert tensor to numpy array\n","\n","        if isinstance(bioclim_sample, torch.Tensor):\n","            bioclim_sample = bioclim_sample.permute(\n","                1, 2, 0\n","            )  # Change tensor shape from (C, H, W) to (H, W, C)\n","            bioclim_sample = bioclim_sample.numpy()  # Convert tensor to numpy array\n","\n","        landsat_sample = self.transform(landsat_sample)\n","        bioclim_sample = self.transform(bioclim_sample)\n","        sentinel_sample = self.sentinel_transform(sentinel_sample)\n","\n","        return tab, landsat_sample, bioclim_sample, sentinel_sample, label, survey_id\n","\n","\n","class TestDataset(TrainDataset):\n","    def __init__(\n","        self,\n","        tab,\n","        bioclim_data_dir,\n","        landsat_data_dir,\n","        sentinel_data_dir,\n","        metadata,\n","        transform=None,\n","    ):\n","        self.tab = tab\n","        self.transform = transform\n","        self.sentinel_transform = transform = SENTINEL_TRANSFORMS\n","\n","        self.bioclim_data_dir = bioclim_data_dir\n","        self.landsat_data_dir = landsat_data_dir\n","        self.sentinel_data_dir = sentinel_data_dir\n","        self.metadata = metadata\n","\n","    def __getitem__(self, idx):\n","        survey_id = self.metadata.surveyId[idx]\n","        tab = torch.Tensor(\n","            self.tab[self.tab[\"surveyId\"] == survey_id].iloc[:, 1:].values[0]\n","        )\n","\n","        landsat_sample = torch.nan_to_num(\n","            torch.load(\n","                os.path.join(\n","                    self.landsat_data_dir,\n","                    f\"GLC24-PA-test-landsat_time_series_{survey_id}_cube.pt\",\n","                )\n","            )\n","        )\n","        bioclim_sample = torch.nan_to_num(\n","            torch.load(\n","                os.path.join(\n","                    self.bioclim_data_dir,\n","                    f\"GLC24-PA-test-bioclimatic_monthly_{survey_id}_cube.pt\",\n","                )\n","            )\n","        )\n","\n","        rgb_sample = np.array(\n","            Image.open(construct_patch_path(self.sentinel_data_dir, survey_id))\n","        )\n","        nir_sample = np.array(\n","            Image.open(\n","                construct_patch_path(\n","                    self.sentinel_data_dir.replace(\"rgb\", \"nir\").replace(\"RGB\", \"NIR\"),\n","                    survey_id,\n","                )\n","            )\n","        )\n","        sentinel_sample = np.concatenate((nir_sample[..., None], rgb_sample), axis=2)\n","\n","        if isinstance(landsat_sample, torch.Tensor):\n","            landsat_sample = landsat_sample.permute(\n","                1, 2, 0\n","            )  # Change tensor shape from (C, H, W) to (H, W, C)\n","            landsat_sample = landsat_sample.numpy()  # Convert tensor to numpy array\n","\n","        if isinstance(bioclim_sample, torch.Tensor):\n","            bioclim_sample = bioclim_sample.permute(\n","                1, 2, 0\n","            )  # Change tensor shape from (C, H, W) to (H, W, C)\n","            bioclim_sample = bioclim_sample.numpy()  # Convert tensor to numpy array\n","\n","        landsat_sample = self.transform(landsat_sample)\n","        bioclim_sample = self.transform(bioclim_sample)\n","        sentinel_sample = self.sentinel_transform(sentinel_sample)\n","\n","        return tab, landsat_sample, bioclim_sample, sentinel_sample, survey_id"]},{"cell_type":"markdown","metadata":{},"source":["### Load metadata and prepare data loaders"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T17:47:47.484413Z","iopub.status.busy":"2024-05-13T17:47:47.48406Z","iopub.status.idle":"2024-05-13T17:47:48.572128Z","shell.execute_reply":"2024-05-13T17:47:48.571186Z","shell.execute_reply.started":"2024-05-13T17:47:47.484389Z"},"trusted":true},"outputs":[],"source":["def create_tab(split: Literal[\"train\", \"test\"]) -> pd.DataFrame:\n","    landcover = pd.read_csv(\n","        f\"{data_dir}/EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-{split}-landcover.csv\"\n","    )\n","    solidgrids = pd.read_csv(\n","        f\"{data_dir}/EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-{split}-soilgrids.csv\"\n","    )\n","    humanfootprint = pd.read_csv(\n","        f\"{data_dir}/EnvironmentalRasters/EnvironmentalRasters/Human Footprint/\"\n","        f\"GLC24-PA-{split}-human_footprint.csv\"\n","    )\n","    elevation = pd.read_csv(\n","        f\"{data_dir}/EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-{split}-elevation.csv\"\n","    )\n","    climate = pd.read_csv(\n","        f\"{data_dir}/EnvironmentalRasters/EnvironmentalRasters/Climate\"\n","        f\"/Average 1981-2010/GLC24-PA-{split}-bioclimatic.csv\"\n","    )\n","    tab = (\n","        climate.merge(elevation, on=\"surveyId\")\n","        .merge(humanfootprint, on=\"surveyId\")\n","        .merge(solidgrids, on=\"surveyId\")\n","        .merge(landcover, on=\"surveyId\")\n","    )\n","    tab = tab.replace(np.inf, np.nan).replace(-np.inf, np.nan)\n","    tab = pd.DataFrame(tab.values, tab.index, tab.columns, dtype=float)\n","    tab = tab.fillna(tab.mean())\n","\n","    return tab\n","\n","\n","train_tab = create_tab(split=\"train\")\n","test_tab = create_tab(split=\"test\")\n","features = train_tab.columns[1:]"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:34.532017Z","start_time":"2024-04-30T21:25:32.615562Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-13T17:47:48.57359Z","iopub.status.busy":"2024-05-13T17:47:48.573327Z","iopub.status.idle":"2024-05-13T17:47:54.449537Z","shell.execute_reply":"2024-05-13T17:47:54.448498Z","shell.execute_reply.started":"2024-05-13T17:47:48.573567Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["# Dataset and DataLoader\n","batch_size = CONFIG[\"batch_size\"]\n","transform = transforms.Compose([transforms.ToTensor()])\n","train_val_split: float = CONFIG[\"train_val_split\"]\n","\n","train_metadata_path = f\"{data_dir}/GLC24_PA_metadata_train.csv\"\n","\n","\n","def dataset_loader():\n","    split_generator = torch.Generator().manual_seed(seed)\n","    train_landsat_data_path = (\n","        f\"{data_dir}/TimeSeries-Cubes/TimeSeries-Cubes/\"\n","        \"GLC24-PA-train-landsat_time_series/\"\n","    )\n","    train_bioclim_data_path = (\n","        f\"{data_dir}/TimeSeries-Cubes/TimeSeries-Cubes/\"\n","        \"GLC24-PA-train-bioclimatic_monthly/\"\n","    )\n","    train_sentinel_data_path = (\n","        f\"{data_dir}/PA_Train_SatellitePatches_RGB/pa_train_patches_rgb/\"\n","    )\n","\n","    metadata = pd.read_csv(train_metadata_path)\n","    dataset = TrainDataset(\n","        train_tab,\n","        train_bioclim_data_path,\n","        train_landsat_data_path,\n","        train_sentinel_data_path,\n","        metadata,\n","        transform=transform,\n","    )\n","\n","    # Load Test metadata\n","    test_landsat_data_path = (\n","        f\"{data_dir}/TimeSeries-Cubes/TimeSeries-Cubes/\"\n","        \"GLC24-PA-test-landsat_time_series/\"\n","    )\n","    test_bioclim_data_path = (\n","        f\"{data_dir}/TimeSeries-Cubes/TimeSeries-Cubes/\"\n","        \"GLC24-PA-test-bioclimatic_monthly/\"\n","    )\n","    test_sentinel_data_path = (\n","        f\"{data_dir}/PA_Test_SatellitePatches_RGB/pa_test_patches_rgb/\"\n","    )\n","    test_metadata_path = f\"{data_dir}/GLC24_PA_metadata_test.csv\"\n","\n","    test_metadata = pd.read_csv(test_metadata_path)\n","    test_dataset = TestDataset(\n","        test_tab,\n","        test_bioclim_data_path,\n","        test_landsat_data_path,\n","        test_sentinel_data_path,\n","        test_metadata,\n","        transform=transform,\n","    )\n","    test_loader = DataLoader(\n","        test_dataset, batch_size=batch_size, shuffle=False, num_workers=4\n","    )\n","\n","    class DatasetIterator:\n","        def __next__(self):\n","            training, validation = random_split(\n","                dataset,\n","                [\n","                    int(len(dataset) * train_val_split),\n","                    len(dataset) - int(len(dataset) * train_val_split),\n","                ],\n","                generator=split_generator,\n","            )\n","            train_loader = DataLoader(\n","                training, batch_size=batch_size, shuffle=True, num_workers=4\n","            )\n","            val_loader = DataLoader(\n","                validation, batch_size=batch_size, shuffle=False, num_workers=4\n","            )\n","            return (train_loader, val_loader), test_loader\n","\n","    return DatasetIterator()"]},{"cell_type":"markdown","metadata":{},"source":["## Define and initialize a Multimodal Model\n","\n","To process multiple inputs with different modalities and formats we use so-call siamiese approach where each modality is processed with different backbone (i.e., encoder). Data encoded into a 1d vector are concatenated and classified with a simple fully connected neural network. Short recap from previous notebooks.\n","- The Landsat cubes have a shape of [6,4,21] (BANDs, QUARTERs, and YEARs).\n","- The Bioclimatic cubes have a shape of [4,19,12] (RASTER-TYPE, YEAR, and MONTH)\n","- The Sentinel Image Patches have a shape od [128, 128, 4] (R, G, B, NIR)"]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:31.014067Z","start_time":"2024-04-30T21:25:31.01006Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-13T17:47:54.450964Z","iopub.status.busy":"2024-05-13T17:47:54.450685Z","iopub.status.idle":"2024-05-13T17:47:54.466746Z","shell.execute_reply":"2024-05-13T17:47:54.465845Z","shell.execute_reply.started":"2024-05-13T17:47:54.45094Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["class MultimodalEnsemble(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.tab_norm = nn.LayerNorm([len(features)])\n","        self.tab_model = nn.Sequential(\n","            nn.Linear(len(features), 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","        )\n","\n","        self.landsat_norm = nn.LayerNorm([6, 4, 21])\n","        self.landsat_model = models.resnet18(weights=None)\n","        # Modify the first convolutional layer to accept 6 channels instead of 3\n","        self.landsat_model.conv1 = nn.Conv2d(\n","            6, 64, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        self.landsat_model.maxpool = nn.Identity()\n","\n","        self.bioclim_norm = nn.LayerNorm([4, 19, 12])\n","        self.bioclim_model = models.resnet18(weights=None)\n","        # Modify the first convolutional layer to accept 4 channels instead of 3\n","        self.bioclim_model.conv1 = nn.Conv2d(\n","            4, 64, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        self.bioclim_model.maxpool = nn.Identity()\n","\n","        self.sentinel_model = models.swin_t(weights=\"IMAGENET1K_V1\")\n","        self.sentinel_model.features[0][0] = nn.Conv2d(\n","            4,\n","            self.sentinel_model.features[0][0].out_channels,\n","            kernel_size=(4, 4),\n","            stride=(4, 4),\n","        )\n","        self.sentinel_model.head = nn.Identity()\n","\n","        self.ln0 = nn.LayerNorm(64)\n","        self.ln1 = nn.LayerNorm(1000)\n","        self.ln2 = nn.LayerNorm(1000)\n","        self.ln3 = nn.LayerNorm(768)\n","\n","        self.fc1 = nn.Linear(\n","            self.ln0.normalized_shape[0]\n","            + self.ln1.normalized_shape[0]\n","            + self.ln2.normalized_shape[0]\n","            + self.ln3.normalized_shape[0],\n","            1024,\n","        )\n","        self.fc2 = nn.Linear(1024, num_classes)\n","\n","        self.dropout = nn.Dropout(p=0.15)\n","\n","    def forward(self, t, x, y, z):\n","        t = self.tab_norm(t)\n","        t = self.tab_model(t)\n","        t = self.ln0(t)\n","        t = self.dropout(t)\n","\n","        x = self.landsat_norm(x)\n","        x = self.landsat_model(x)\n","        x = self.ln1(x)\n","        x = self.dropout(x)\n","\n","        y = self.bioclim_norm(y)\n","        y = self.bioclim_model(y)\n","        y = self.ln2(y)\n","        y = self.dropout(y)\n","\n","        z = self.sentinel_model(z)\n","        z = self.ln3(z)\n","        z = self.dropout(z)\n","\n","        txyz = torch.cat((t, x, y, z), dim=1)\n","\n","        txyz = self.fc1(txyz).relu()\n","        txyz = self.dropout(txyz)\n","\n","        out = self.fc2(txyz)\n","        return out\n","\n","\n","model = MultimodalEnsemble(num_classes).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Training Loop\n","\n","Nothing special, just a standard Pytorch training loop."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def calculate_f1_score(pred: np.ndarray, gt):\n","    list_f1 = []\n","    for p, g in zip(pred, gt, strict=False):\n","        sp = set(p)\n","        sg = set(g)\n","        TP = len(list(sp.intersection(sg)))\n","        FP = len(list(sp - sg))\n","        FN = len(list(sg - sp))\n","        f1 = TP / (TP + (FP + FN) / 2)\n","        list_f1.append(f1)\n","    return np.mean(list_f1)\n","\n","\n","def f1_score_and_top_k(survey_ids, predictions):\n","    train_pa = pd.read_csv(train_metadata_path)[[\"surveyId\", \"speciesId\"]]\n","    train_pa[train_pa.columns] = train_pa[train_pa.columns].astype(int)\n","    gt = [\n","        train_pa[train_pa[\"surveyId\"] == surveyId].speciesId.values.tolist()\n","        for surveyId in survey_ids\n","    ]\n","    pred_sorted = np.argsort(-np.array(predictions), axis=1)\n","    best_top_k = 1\n","    best_score = 0\n","\n","    for k in range(1, 100):\n","        top_k = pred_sorted[:, :k].tolist()\n","        score = calculate_f1_score(top_k, gt)\n","        if score > best_score:\n","            best_score = score\n","            best_top_k = k\n","    return best_score, best_top_k"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def calculate_pos_weights(dl: DataLoader) -> torch.Tensor:\n","    df = pd.read_csv(train_metadata_path)\n","    survey_ids = [df.loc[i, \"surveyId\"] for i in dl.dataset.indices]\n","    df = df[[\"surveyId\", \"speciesId\"]][df.surveyId.isin(survey_ids)]\n","    df = df.drop_duplicates()\n","\n","    pos_counts = df.groupby(\"speciesId\")[\"surveyId\"].nunique()\n","\n","    output = torch.zeros(num_classes, dtype=torch.float32)\n","    num_samples = df.surveyId.nunique()\n","    weights = pos_counts.values\n","    weights = weights / (num_samples - weights)\n","    output[pos_counts.index.astype(int).to_numpy()] = torch.from_numpy(\n","        weights.astype(np.float32)\n","    )\n","    return output.to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"start_time":"2024-04-30T21:25:34.536634Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-13T17:47:57.488663Z","iopub.status.busy":"2024-05-13T17:47:57.488327Z","iopub.status.idle":"2024-05-13T17:50:06.757917Z","shell.execute_reply":"2024-05-13T17:50:06.755777Z","shell.execute_reply.started":"2024-05-13T17:47:57.488633Z"},"is_executing":true,"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bc2180f9bf742db999418edd8490bf0","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2c850c64427435891e10159cad250ef","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Hyperparameters\n","\n","learning_rate = CONFIG[\"learning_rate\"]\n","num_epochs = CONFIG[\"num_epochs\"]\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","best_val = None\n","early_stopping_delay = CONFIG[\"early_stopping_delay\"]\n","\n","dataset_iter = dataset_loader()\n","\n","best_ago = 0\n","\n","criterion = torch.nn.BCEWithLogitsLoss()\n","(train_loader, val_loader), test_loader = next(dataset_iter)\n","batch_pbar = tqdm(position=1, leave=True)\n","for epoch in tqdm(range(num_epochs), desc=\"Epoch\", position=1):\n","    criterion.register_buffer(\"pos_weight\", calculate_pos_weights(train_loader))\n","\n","    # training\n","    total = 0\n","    total_loss = 0\n","    model.train()\n","    batch_pbar.reset(len(train_loader))\n","    batch_pbar.desc = f\"Train {epoch}/{num_epochs}\"\n","    for batch_idx, (data0, data1, data2, data3, targets, _) in enumerate(train_loader):\n","        batch_pbar.update()\n","        data0 = data0.to(device)\n","        data1 = data1.to(device)\n","        data2 = data2.to(device)\n","        data3 = data3.to(device)\n","        targets = targets.to(device)\n","\n","        # Mixup\n","        if np.random.rand() < 0.4:\n","            lam = torch.tensor(np.random.beta(0.4, 0.4)).to(device)\n","            rand_index = torch.randperm(data0.size()[0]).to(device)\n","            mixed_data0 = lam * data0 + (1 - lam) * data0[rand_index]\n","            mixed_data1 = lam * data1 + (1 - lam) * data1[rand_index]\n","            mixed_data2 = lam * data2 + (1 - lam) * data2[rand_index]\n","            mixed_data3 = lam * data3 + (1 - lam) * data3[rand_index]\n","            targets_a, targets_b = targets, targets[rand_index]\n","            mixed_targets = lam * targets_a + (1 - lam) * targets_b\n","            outputs = model(mixed_data0, mixed_data1, mixed_data2, mixed_data3)\n","            loss = criterion(outputs, mixed_targets)\n","        else:\n","            outputs = model(data0, data1, data2, data3)\n","            loss = criterion(outputs, targets)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += data1.shape[0]\n","        total_loss += loss.item() * data1.shape[0]\n","\n","        if DEBUG and batch_idx > 50:\n","            break\n","\n","    total_loss /= total\n","\n","    vtotal = 0\n","    vtotal_loss = 0\n","    model.eval()\n","    with torch.no_grad():\n","        batch_pbar.desc = f\"Val {epoch}/{num_epochs}\"\n","        batch_pbar.reset(len(val_loader))\n","        all_predictions = []\n","        all_surveyID = []\n","        for batch_idx, (data0, data1, data2, data3, targets, surveyID) in enumerate(\n","            val_loader\n","        ):\n","            batch_pbar.update()\n","            data0 = data0.to(device)\n","            data1 = data1.to(device)\n","            data2 = data2.to(device)\n","            data3 = data3.to(device)\n","            targets = targets.to(device)\n","\n","            outputs = model(data0, data1, data2, data3)\n","            predictions = torch.sigmoid(outputs).cpu().numpy()\n","\n","            all_predictions.extend(predictions)\n","            all_surveyID.extend(surveyID.numpy())\n","\n","            loss = criterion(outputs, targets)\n","\n","            vtotal += data1.shape[0]\n","            vtotal_loss += loss.item() * data1.shape[0]\n","\n","            if DEBUG and batch_idx > 50:\n","                break\n","        f1_score, best_top_k = f1_score_and_top_k(all_surveyID, all_predictions)\n","        vtotal_loss /= vtotal\n","        tb_writer.add_scalar(\"train/loss\", total_loss, epoch)\n","        tb_writer.add_scalar(\"val/loss\", vtotal_loss, epoch)\n","        tb_writer.add_scalar(\"val/f1_score\", f1_score, epoch)\n","\n","    torch.save(model.eval().state_dict(), os.path.join(output_dir, \"last.pth\"))\n","    if best_val is None or vtotal_loss < best_val:\n","        best_val = vtotal_loss\n","        torch.save(model.eval().state_dict(), os.path.join(output_dir, \"best.pth\"))\n","        with open(os.path.join(output_dir, \"thresholds.json\"), \"w\") as fp:\n","            json.dump({\"f1_score\": f1_score, \"best_top_k\": best_top_k}, fp)\n","        best_ago = 0\n","        continue\n","    best_ago += 1\n","    if best_ago == early_stopping_delay:\n","        print(\n","            f\"Stopping at epoch {epoch} as no improvement for {early_stopping_delay}\"\n","            \" epochs.\"\n","        )\n","        break\n","tb_writer.close()"]},{"cell_type":"markdown","metadata":{},"source":["## Test Loop\n"]},{"cell_type":"markdown","metadata":{},"source":["Find top k for best model"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["with open(os.path.join(output_dir, \"thresholds.json\")) as fp:\n","    best_top_k = json.load(fp)[\"best_top_k\"]"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"execution":{"iopub.status.busy":"2024-05-13T17:50:06.767528Z","iopub.status.idle":"2024-05-13T17:50:06.767825Z","shell.execute_reply":"2024-05-13T17:50:06.767687Z","shell.execute_reply.started":"2024-05-13T17:50:06.767675Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9ae8015a77a4bdea8baa6a076b5a517","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/37 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["with torch.no_grad():\n","    all_predictions = []\n","    surveys = []\n","    top_k_indices = None\n","    for data0, data1, data2, data3, surveyID in tqdm(test_loader):\n","        data0 = data0.to(device)\n","        data1 = data1.to(device)\n","        data2 = data2.to(device)\n","        data3 = data3.to(device)\n","\n","        outputs = model(data0, data1, data2, data3)\n","        predictions = torch.sigmoid(outputs).cpu().numpy()\n","\n","        # Select top-k values as predictions\n","        top_k = np.argsort(-predictions, axis=1)[:, :best_top_k]\n","        if top_k_indices is None:\n","            top_k_indices = top_k\n","        else:\n","            top_k_indices = np.concatenate((top_k_indices, top_k), axis=0)\n","\n","        surveys.extend(surveyID.cpu().numpy())"]},{"cell_type":"markdown","metadata":{},"source":["## Save prediction file! 🎉🥳🙌🤗"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.status.busy":"2024-05-13T17:50:06.768691Z","iopub.status.idle":"2024-05-13T17:50:06.768979Z","shell.execute_reply":"2024-05-13T17:50:06.768847Z","shell.execute_reply.started":"2024-05-13T17:50:06.768834Z"},"tags":[],"trusted":true},"outputs":[],"source":["data_concatenated = [\" \".join(map(str, row)) for row in top_k_indices]\n","\n","pd.DataFrame(\n","    {\n","        \"surveyId\": surveys,\n","        \"predictions\": data_concatenated,\n","    }\n",").to_csv(os.path.join(output_dir, \"submission.csv\"), index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8171035,"sourceId":64733,"sourceType":"competition"}],"dockerImageVersionId":30699,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
